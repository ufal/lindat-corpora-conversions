#(partially copied from Ondrej Dusek script with cnk)
SHELL = bash
PLAIN_PATH=/net/cluster/TMP/vernerova/kontext/cwc/input
TMP_PATH=/net/cluster/TMP/vernerova/kontext/cwc/tmp
PARSE_PATH=/net/cluster/TMP/vernerova/kontext/cwc/output
TMP_PATH_TEST=/net/cluster/TMP/vernerova/kontext/cwc/tmp_test
PARSE_PATH_TEST=/net/cluster/TMP/vernerova/kontext/cwc/output_test
OUTFILE=/net/cluster/TMP/vernerova/kontext/cwc/output/vertical_all

#OUTFOLDER=/net/cluster/TMP/vernerova/kontext/cwc/output
PARALLEL=1
ifdef P # Shortcut P -> PARALLEL
  PARALLEL := $(P)
endif
SCRIPTS=~/tectomt/treex/devel/analysis/cs/cnk/extras
# "Survive" by default (turn off by setting empty value)
SURVIVE := --survive

# Parallel processing settings (default: 6 files per job per subdirectory)
ifeq ($(PARALLEL), 1)
  QUEUE := '*'
  MEM=8G
  QPARAMS := "-q $(QUEUE)"
  JOBS=50
  FLAGS= --parallel --qsub=$(QPARAMS) --jobs=$(JOBS) $(SURVIVE) --mem=$(MEM)
endif
ifdef J # Shortcut J -> JOBS
  JOBS := $(J)
endif

# Default: split files at 200 sentences
SPLIT=200

info:
	@echo 'Parsing a plaintext'
	@echo 'Input directory: $(PLAIN_PATH)'
	@echo 'Output directory: $(PARSE_PATH)'

prepare_subdirs:
	ls $(PLAIN_PATH) | while read dir; do mkdir $(PARSE_PATH)/$$dir; done

#parse: TARGET_PATH=$(PARSE_PATH)
#parse: FILE=*.txt
parse:        
	treex --language=cs $(FLAGS) \
		Read::Sentences from="!$(TMP_PATH)/*/*" \
		W2A::CS::Tokenize \
                W2A::CS::TagMorphoDiTa lemmatize=1 \
                W2A::CS::FixMorphoErrors \
                W2A::CS::ParseMSTAdapted \
                Write::Manatee substitute={$(TMP_PATH)}{$(PARSE_PATH)}

clean:
	#rm -r $(PARSE_PATH)/_treex-run
	rm -r $(TMP_PATH)/d*
	rm -r $(PARSE_PATH)/d*

split:
	./split_to_dirs.pl $(TMP_PATH) 200 < $(PLAIN_PATH)/plain_concatenated

concatenate:
	echo "<doc>" > $(OUTFILE)
	find $(PARSE_PATH)/ -iname '*.vert' -exec cat {} \; >> $(OUTFILE)
	echo "</doc>" >> $(OUTFILE)
